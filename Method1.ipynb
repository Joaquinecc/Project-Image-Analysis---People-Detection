{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4595b1-3238-4f28-a51c-3e3ea1fb506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "bg_path= \"data/images/1660712400.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1995911-4a44-42fd-85b1-0abbc16b1cd2",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ddc19c-e014-40fb-8bda-33a490dfbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beach_mask(bg_path):\n",
    "    \"\"\"\n",
    "    Generates a mask highlighting the beach area from a given background image.\n",
    "\n",
    "    This function processes the input image by applying several image processing techniques \n",
    "    such as grayscale conversion, Gaussian blurring, thresholding, dilation, and noise removal \n",
    "    to segment the beach area. It also identifies and combines lake/sky and mountain regions \n",
    "    to improve the segmentation of the beach area.\n",
    "\n",
    "    Args:\n",
    "        bg_path (str): The path to the input background image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A binary mask (numpy array) where the beach area is marked as 255 \n",
    "                        (white), and all other areas are 0 (black).\n",
    "    \"\"\"\n",
    "    #Lake\n",
    "    bg_img= cv2.imread(bg_path)\n",
    "    bg_img=cv2.cvtColor(bg_img,cv2.COLOR_BGR2GRAY)\n",
    "    bg_img= cv2.GaussianBlur(bg_img,(5,5),0)\n",
    "    ret,bg_img = cv2.threshold(bg_img,120,255,cv2.THRESH_BINARY)\n",
    "    kernel=np.ones((5,5))\n",
    "    bg_img = cv2.dilate(bg_img,kernel,iterations = 4)\n",
    "    mask_lake_sky=bg_img>0\n",
    "\n",
    "    #mountain\n",
    "    bg_img= cv2.imread(bg_path)\n",
    "    bg_img=cv2.cvtColor(bg_img,cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE()\n",
    "    bg_img= cv2.GaussianBlur(bg_img,(5,5),0)\n",
    "    bg_img = cv2.dilate(bg_img,kernel,iterations = 4)\n",
    "    ret,mountain_bg = cv2.threshold(bg_img,90,255,cv2.THRESH_BINARY_INV)\n",
    "    mountain_bg[mask_lake_sky]=0\n",
    "    mask_mountain_bg=mountain_bg>0\n",
    "\n",
    "    #Remove noise\n",
    "    img=cv2.imread(bg_path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img= cv2.GaussianBlur(img,(5,5),0)\n",
    "    img[mask_lake_sky] = 0\n",
    "    img[mask_mountain_bg] = 0\n",
    "    ret,img = cv2.threshold(img,20,255,cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img=  cv2.erode(img, kernel) \n",
    "\n",
    "\n",
    "    analysis = cv2.connectedComponentsWithStats(img, \n",
    "                                            4, \n",
    "                                            cv2.CV_32S) \n",
    "    (totalLabels, label_ids, values, centroid) = analysis \n",
    "    totalLabels,cv2.CC_STAT_AREA\n",
    "    output = np.zeros(img.shape, dtype=\"uint8\")\n",
    "    idx= np.where(values[:, cv2.CC_STAT_AREA]>10000)[0]\n",
    "    i=idx[-1]\n",
    "    area = values[i, cv2.CC_STAT_AREA]   \n",
    "    \n",
    "    # Labels stores all the IDs of the components on the each pixel \n",
    "    # It has the same dimension as the threshold \n",
    "    # So we'll check the component \n",
    "    # then convert it to 255 value to mark it white \n",
    "    componentMask = (label_ids == i).astype(\"uint8\") * 255\n",
    "      \n",
    "    # Creating the Final output mask \n",
    "    output = cv2.bitwise_or(output, componentMask)\n",
    "    \n",
    "    kernel=np.ones((15,15))\n",
    "    output = cv2.dilate(output,kernel,iterations = 5)\n",
    "    \n",
    "    kernel=np.ones((10,10))\n",
    "    \n",
    "    output = cv2.morphologyEx(output, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    beach_mask= output>0\n",
    "\n",
    "    return beach_mask\n",
    "\n",
    "\n",
    "def compute_image_metric_level_table(predictions_points,gt_points, MAX_ERROR_DISTANCE):\n",
    "    \"\"\"\n",
    "    Computes a table of image metric results for comparing predicted points against ground truth points.\n",
    "    This function calculates the Euclidean distance between each predicted point and ground truth points, \n",
    "    and determines whether each predicted point is a true positive (TP), false positive (FP), or a false negative (FN).\n",
    "    \n",
    "    The result is a table of predictions with corresponding ground truth matches, and the number of false negatives.\n",
    "\n",
    "    Args:\n",
    "        predictions_points (numpy.ndarray): A 2D array of shape (N, 2) where each row represents a predicted point \n",
    "                                             with (x, y) coordinates.\n",
    "        gt_points (numpy.ndarray): A 2D array of shape (M, 2) where each row represents a ground truth point \n",
    "                                    with (x, y) coordinates.\n",
    "        MAX_ERROR_DISTANCE (float): The maximum allowable Euclidean distance to consider a match between a \n",
    "                                     predicted point and a ground truth point.\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - table_results (numpy.ndarray): A 2D array of shape (N, 6) with columns:\n",
    "                (pred_x, pred_y, tp, fp, matched_gt_x, matched_gt_y)\n",
    "                where `tp` is 1 if the predicted point is a true positive, `fp` is 1 if it's a false positive, \n",
    "                and `matched_gt_x`, `matched_gt_y` are the coordinates of the matched ground truth point (or None if no match).\n",
    "                \n",
    "            - fn (int): The number of false negatives, i.e., the number of ground truth points that were not matched to any prediction.\n",
    "\n",
    "    \"\"\"\n",
    "    gt_points_remaining = gt_points.copy()  # Copy the ground truth points to keep track of unmatched ones\n",
    "    table_results = []  # To store results as a list of tuples: (pred_x, pred_y, tp, fp, gt_x, gt_y)\n",
    "    for pred in predictions_points:\n",
    "        best_distance_match = 900  # Initialize best match distance as a large number\n",
    "        best_idx_match = -1  # Index of the best match ground truth poin\n",
    "        # Iterate over remaining ground truth points\n",
    "        for idx, gt in enumerate(gt_points_remaining):\n",
    "            # Calculate Euclidean distance using np.linalg.norm\n",
    "            eucledian_distance = np.linalg.norm(pred - gt)  # Pred and gt are arrays or tuples, eucledian_distance is a scalar\n",
    "            # Check if this is the best (smallest) distance so far\n",
    "            if eucledian_distance < best_distance_match:\n",
    "                best_distance_match = eucledian_distance\n",
    "                best_idx_match = idx  # Store the index of the matching ground truth point\n",
    "    \n",
    "        # Check if the best match is within the allowable error distance\n",
    "        if best_distance_match <= MAX_ERROR_DISTANCE:\n",
    "            # Add the match result to the table: (pred_x, pred_y, tp, fp, matched_gt_x, matched_gt_y)\n",
    "            table_results.append((pred[0], pred[1], 1, 0, gt_points_remaining[best_idx_match][0], gt_points_remaining[best_idx_match][1]))\n",
    "            # Remove the matched ground truth point from the remaining list\n",
    "            gt_points_remaining = np.delete(gt_points_remaining, best_idx_match, axis=0)\n",
    "        else:\n",
    "            # If no match is found within the error distance, mark it as a false positive\n",
    "            table_results.append((pred[0], pred[1], 0, 1, None, None))\n",
    "    table_results= np.array(table_results)\n",
    "    fn = len(gt_points_remaining)  # Already calculated earlier\n",
    "    return table_results,fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf194b-5d58-4ec5-aaf0-c056d3101dae",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d9cfbb-651c-43a0-9ed5-a2138ee60500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@41.610] global loadsave.cpp:241 findDecoder imread_('images/1660712400.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m images_path \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      4\u001b[0m images_path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(images_path, \u001b[38;5;241m0\u001b[39m, bg_path, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m beach_mask \u001b[38;5;241m=\u001b[39m \u001b[43mget_beach_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mlen\u001b[39m(images_path)\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mget_beach_mask\u001b[0;34m(bg_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#Lake\u001b[39;00m\n\u001b[1;32m     18\u001b[0m bg_img\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(bg_path)\n\u001b[0;32m---> 19\u001b[0m bg_img\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m bg_img\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(bg_img,(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m),\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m ret,bg_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(bg_img,\u001b[38;5;241m120\u001b[39m,\u001b[38;5;241m255\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('data/annotation_points.csv',header=None)\n",
    "df.columns= ['label','x','y','filename','witdth','height']\n",
    "images_path =  \"data/images/\"+df.filename.unique()\n",
    "images_path = np.insert(images_path, 0, bg_path, axis=0)\n",
    "beach_mask = get_beach_mask(bg_path)\n",
    "len(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292241e-4095-498a-b670-9e7d338c4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_image_level=[]\n",
    "metrics_person_level=[]\n",
    "fn_global=0\n",
    "theshold_person= 90\n",
    "for img_path in images_path:\n",
    "    img=cv2.imread(img_path)\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_img= cv2.GaussianBlur(gray_img,(5,5),0)\n",
    "    ret,gray_img = cv2.threshold(gray_img,theshold_person,255,cv2.THRESH_BINARY_INV)\n",
    "    gray_img[~beach_mask] = 0\n",
    "\n",
    "    # Apply the Component analysis function \n",
    "    analysis = cv2.connectedComponentsWithStats(gray_img,4,cv2.CV_32S) \n",
    "    (totalLabels, label_ids, values, centroid) = analysis \n",
    "    predictions_indx=(values[:, cv2.CC_STAT_AREA]  > 50) & (values[:, cv2.CC_STAT_AREA]  < 1000)\n",
    "    predictions_points = centroid[predictions_indx]  # Get predicted points\n",
    "    #Compute metrics\n",
    "    filename= img_path.replace(\"images/\",\"\")\n",
    "    gt_points = df[df.filename == filename][['x', 'y']].to_numpy()  # Get ground truth points as a numpy array\n",
    "    \n",
    "    metrics_image_level.append([filename, len(gt_points), len(predictions_points),] )\n",
    "\n",
    "    MAX_ERROR_DISTANCE=130\n",
    "    temp,fn = compute_image_metric_level_table(predictions_points,gt_points, MAX_ERROR_DISTANCE)\n",
    "    fn_global+=fn\n",
    "    new_col_filename = np.full((len(temp),1),filename)\n",
    "    new_col_fn = np.full((len(temp),1),fn)\n",
    "    temp = np.append(new_col_filename,temp,axis=1)\n",
    "    temp = np.append(temp,new_col_fn, axis=1)\n",
    "    if len(metrics_person_level)>0:\n",
    "        metrics_person_level= np.concatenate((metrics_person_level,temp),axis=0)\n",
    "    else:\n",
    "        metrics_person_level = temp\n",
    "metrics_image_level=np.array(metrics_image_level)\n",
    "df_results_image = pd.DataFrame(metrics_image_level, columns=['filename','gt', 'pred'])\n",
    "df_results_person = pd.DataFrame(metrics_person_level, columns=['filename','pred_x', 'pred_y', 'tp', 'fp', 'gt_x', 'gt_y','fn'])\n",
    "# df_results_person.head()\n",
    "\n",
    "metrics_image_level=np.array(metrics_image_level)\n",
    "df_results_image = pd.DataFrame(metrics_image_level, columns=['filename','gt', 'pred'])\n",
    "df_results_person = pd.DataFrame(metrics_person_level, columns=['filename','pred_x', 'pred_y', 'tp', 'fp', 'gt_x', 'gt_y','fn'])\n",
    "# df_results_person.head()\n",
    "df_aggregated = df_results_person.groupby('filename').agg({\n",
    "    'tp': 'sum',   # Sum tp values\n",
    "    'fp': 'sum',   # Sum fp values\n",
    "    'fn': 'max'    # Take the max fn value\n",
    "}).reset_index()\n",
    "df_aggregated['precision'] = df_aggregated.tp /(df_aggregated.tp + df_aggregated.fp)*100\n",
    "# df_aggregated['recall'] = df_aggregated.tp /(df_aggregated.tp + df_aggregated.fn)*100 if  df_aggregated.fn> 0 else 0\n",
    "def calculate_recall(row):\n",
    "    if row['fn'] > 0:\n",
    "        return (row['tp'] / (row['tp'] + row['fn'])) * 100\n",
    "    else:\n",
    "        return 0\n",
    "df_aggregated['recall'] = df_aggregated.apply(calculate_recall, axis=1)\n",
    "df_aggregated['accurac'] = df_aggregated.tp /(df_aggregated.tp + df_aggregated.fp+df_aggregated.fn)*100\n",
    "\n",
    "df_results_image.gt = df_results_image['gt'].astype(int)\n",
    "df_results_image.pred = df_results_image['pred'].astype(int)\n",
    "df_results_image[\"MSE\"]=(df_results_image.gt - df_results_image.pred)**2\n",
    "df_aggregated = df_aggregated.merge(df_results_image,how='inner',on='filename')\n",
    "df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256176d-02d2-4062-a83b-ef9bfcb2b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated.to_csv(\"results.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e2a51-b7e9-44fd-9f31-fbed04209dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Mean Square ERRor\n",
    "mse = df_results_image[\"MSE\"].sum()/len(df_results_image)\n",
    "print(\"Mean Square Error \",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf5ecc-13cc-4d57-81c3-38bf44079171",
   "metadata": {},
   "source": [
    "# Plot Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae5363-9652-4956-b616-0bc9676faf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filesnames = df_results_person.filename.unique()\\\n",
    "# filename = filesnames[random.randint(0,len(filesnames)-1)]\n",
    "filename= '1660752000.jpg'\n",
    "df_sample = df_results_person[df_results_person.filename  == filename]\n",
    "df_sample_gt= df[df.filename == filename]\n",
    "img= cv2.imread(f\"images/{filename}\")\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(20,15))\n",
    "# plt.scatter(df_sample['x'],df_sample['y'], c =\"blue\")\n",
    "plt.imshow(img)\n",
    "df_tp= df_sample[df_sample.tp == 1]\n",
    "df_fp= df_sample[df_sample.fp == 1]\n",
    "\n",
    "plt.scatter(df_sample_gt['x'],df_sample_gt['y'], c =\"blue\")\n",
    "plt.scatter(df_tp['pred_x'],df_tp['pred_y'], c =\"green\")\n",
    "plt.scatter(df_fp['pred_x'],df_fp['pred_y'], c =\"red\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hope",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
